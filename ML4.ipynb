{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGClrhQA9SAk"
      },
      "source": [
        "# Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veekMy8WRjBi"
      },
      "source": [
        "## Построение дерева"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkVwAFiUHXj"
      },
      "source": [
        "Опишем жадный алгоритм построения бинарного дерева решений:\n",
        "1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$. \n",
        "2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки. \n",
        "3. Запускаем построение из корня: $SplitNode(1, R_1)$\n",
        "\n",
        "Функция $SplitNode(m, R_m)$\n",
        "1. Если выполнен критерий остановки, то выход.\n",
        "2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n",
        "3. Помещаем предикат в вкршину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n",
        "4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n",
        "5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n",
        "\n",
        "В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n",
        "$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P6FsdBog4Ai"
      },
      "source": [
        "## Функционал качества для деревьев решений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAKO0aykGBD"
      },
      "source": [
        "Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n",
        "$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5582B-1Fn2bw"
      },
      "source": [
        "где $p_i$ – вероятности нахождения системы в $i$-ом состоянии. \n",
        "\n",
        "Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmN6V_N1xBr"
      },
      "source": [
        "\n",
        "### Задание 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFHZScF2CBF"
      },
      "source": [
        "Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения дерева (используйте `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признакоd и порогов), для проверки критерия остановки.\n",
        "\n",
        "Для набора данных `iris` реализуйте алгоритм и минимум три из разными критерия остановки из перечисленных ниже:\n",
        "* максимальной глубины дерева = 5\n",
        "* минимального числа объектов в листе = 5\n",
        "* максимальное количество листьев в дереве = 5\n",
        "* purity (остановка, если все объекты в листе относятся к одному классу)\n",
        "\n",
        "Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n",
        "\n",
        "Оцените точность каждой модели с помощью метрики точность (`from sklearn.metrics import accuracy_score` или реализовать свою)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbcMUd7bvk05"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "561e37RVLk7E"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g_WlqP2FsCx"
      },
      "source": [
        "class DecisionTree:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def fit(self, df):\n",
        "    self.train = df\n",
        "    self.result = pd.DataFrame([])\n",
        "\n",
        "  def entropy(self,y):\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "    return entropy\n",
        "\n",
        "  def compute_information_gain(self, df, left, right):\n",
        "    if left.shape[0] == 0:\n",
        "      return 0\n",
        "    if right.shape[0] == 0:\n",
        "      return 0\n",
        "    HRv = self.entropy(df['y'])\n",
        "    cntRv = df.shape[0]\n",
        "    cntRleft = left.shape[0]\n",
        "    cntRright = right.shape[0]\n",
        "    HRleft = self.entropy(left['y'])\n",
        "    HRright = self.entropy(right['y'])\n",
        "    return HRv - ((cntRleft/cntRv)*HRleft + (cntRright/cntRv)*HRright)\n",
        "\n",
        "  def find_best_split(self, df):\n",
        "    grid = np.linspace(df[0].min(), df[0].max(), 10)\n",
        "    best_t = grid[0]\n",
        "    best_IG = -1\n",
        "    for attr in range(df.shape[1]-1):\n",
        "      grid = np.linspace(df[attr].min(), df[attr].max(), 10)\n",
        "      for split_point in grid:\n",
        "        left = df[df[attr] < split_point]\n",
        "        right = df[df[attr] >= split_point]\n",
        "        IG = self.compute_information_gain(df, left, right)\n",
        "        if IG > best_IG:\n",
        "          best_t, best_IG  = split_point, IG\n",
        "          best_attr = attr\n",
        "    return best_t, best_attr   \n",
        "  \n",
        "  def build_tree(self, df_train, df_test, criterion, depth, CNT):\n",
        "    CNT += 2\n",
        "    if self.stop_criterion(criterion, df_train, depth, CNT):\n",
        "      if df_test.shape[0] > 0:\n",
        "        df_test['y'] = df_train['y'].value_counts().idxmax()\n",
        "        self.result = self.result.append(df_test)\n",
        "        return self\n",
        "    else:\n",
        "      split_point, attr = self.find_best_split(df_train)\n",
        "      self.build_tree(df_train[df_train[attr] < split_point], df_test[df_test[attr] < split_point], criterion, depth+1, CNT)\n",
        "      self.build_tree(df_train[df_train[attr] >= split_point], df_test[df_test[attr] >= split_point], criterion, depth+1, CNT)\n",
        "\n",
        "  def stop_criterion(self, criterion, df, depth, CNT):\n",
        "    if criterion == 'max_depth':\n",
        "      if depth == 5:\n",
        "        return True\n",
        "    if criterion == 'max_leaf':\n",
        "      if CNT == 5:\n",
        "        return True\n",
        "    if criterion == 'purity':\n",
        "      df1 = df[df['y'] == 0]\n",
        "      df2 = df[df['y'] == 1]\n",
        "      df3 = df[df['y'] == 2]\n",
        "      if df1.shape[0] == df.shape[0] or df2.shape[0] == df.shape[0] or df3.shape[0] == df.shape[0]:\n",
        "        return True\n",
        "    return False\n",
        "  def accuracy(self, y_test, y_pred):\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for i in range(len(y_pred)):\n",
        "      if y_pred[i] == y_test[i] == 1:\n",
        "        tp=tp+1\n",
        "      if y_pred[i]==0 and y_pred[i]!=y_test[i]:\n",
        "        fn=fn+1\n",
        "      if y_pred[i]==1 and y_pred[i]!=y_test[i]:\n",
        "        fp=fp+1\n",
        "      if y_pred[i] == y_test[i] == 0:\n",
        "        tn=tn+1\n",
        "    return (tp + tn)/(tp + fp + tn + fn)\n",
        "\n",
        "  def predict(self, df_test, criterion):\n",
        "    self.build_tree(self.train, df_test, criterion, 0, -1)\n",
        "    self.result.sort_index(inplace=True)\n",
        "    return self.result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLlHzzkKEmYT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "pd.options.mode.chained_assignment = None\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.33, random_state=6011981)\n",
        "\n",
        "df_train=pd.DataFrame(X_train)\n",
        "df_train['y']=y_train\n",
        "\n",
        "df_test=pd.DataFrame(X_test)\n",
        "df_test['y']=y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWlZfSmNIWOC",
        "outputId": "7e62f9be-1ba8-401d-8556-53f09858ae12"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "tree_1=DecisionTree()\n",
        "tree_1.fit(df_train)\n",
        "df_test_1 = tree_1.predict(df_test, 'max_leaf')\n",
        "y_pred_1=df_test_1['y'].values\n",
        "print(\"My accuracy_score: \", tree_1.accuracy(y_test, y_pred_1), \" sklearn accuracy_score: \", accuracy_score(y_test, y_pred_1))\n",
        "tree_2=DecisionTree()\n",
        "tree_2.fit(df_train)\n",
        "df_test_2 = tree_2.predict(df_test, 'max_depth')\n",
        "y_pred_2=df_test_2['y'].values\n",
        "print(\"My accuracy_score: \", tree_2.accuracy(y_test, y_pred_2), \" sklearn accuracy_score: \", accuracy_score(y_test, y_pred_2))\n",
        "tree_3=DecisionTree()\n",
        "tree_3.fit(df_train)\n",
        "df_test_3 = tree_3.predict(df_test, 'purity')\n",
        "y_pred_3=df_test_3['y'].values\n",
        "print(\"My accuracy_score: \", tree_3.accuracy(y_test, y_pred_3), \" sklearn accuracy_score: \", accuracy_score(y_test, y_pred_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My accuracy_score:  0.9696969696969697  sklearn accuracy_score:  0.98\n",
            "My accuracy_score:  0.8648648648648649  sklearn accuracy_score:  0.9\n",
            "My accuracy_score:  0.8421052631578947  sklearn accuracy_score:  0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZzPZvxZ1xBU"
      },
      "source": [
        "В итоге получилось так что взятые мной 3 критерия остановки на основе этой выборки показали высокий результат, но max_leaf лучше всего. При этом значение моей реализации функции accuracy_score сильно отличается от sklearn (sklearn работает лучше)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyCjLcy_CTM"
      },
      "source": [
        "##  Случайный лес"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKZe1FyRgCa"
      },
      "source": [
        "Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n",
        "\n",
        "1. Зададим $N$ - число деревьев в лесу.\n",
        "2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n",
        "3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n",
        "4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBQ8lc0WyrN"
      },
      "source": [
        "### Задание 4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y594Jn04ZTCm"
      },
      "source": [
        "В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n",
        "\n",
        "Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be_mLbdVW2oG"
      },
      "source": [
        "Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\". \n",
        "\n",
        "Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n",
        "\n",
        "Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n",
        "\n",
        "В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hau_VbWeC85R",
        "outputId": "9a9b6eb9-d327-44b3-ea9d-d945f10024cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgzCaDRKTS0r"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        " \n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U3t4sWY7Ykd"
      },
      "source": [
        "Предобработаем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "3QWmPJS8TZy0",
        "outputId": "27f11967-b8cf-4375-e358-49bb423a64e1"
      },
      "source": [
        "training_data = pd.read_csv('/content/drive/MyDrive/data/churn.csv')\n",
        "training_points = training_data.drop([\"RowNumber\", \"CustomerId\", \"Surname\", \"Exited\"], axis=1)\n",
        "training_values = training_data.Exited\n",
        "training_points.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  HasCrCard  IsActiveMember  EstimatedSalary\n",
              "0          619    France  Female  ...          1               1        101348.88\n",
              "1          608     Spain  Female  ...          0               1        112542.58\n",
              "2          502    France  Female  ...          1               0        113931.57\n",
              "3          699    France  Female  ...          0               0         93826.63\n",
              "4          850     Spain  Female  ...          1               1         79084.10\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgg_mqas7eI6"
      },
      "source": [
        "Применим LabelEncoder к категорильным признакам: Geography и Gender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "3uDyH1qATtP7",
        "outputId": "9a7de846-fdde-4f19-f402-340f3e75087b"
      },
      "source": [
        "def encoding(df, features):\n",
        "  X_enc = df.copy()\n",
        "  training_points = pd.get_dummies(X_enc, columns=features)\n",
        "  return training_points\n",
        "categorial = ['Gender','Geography']\n",
        "training_points = encoding(training_points, categorial)\n",
        "training_points.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Geography_France</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  ...  Geography_Germany  Geography_Spain\n",
              "0          619   42  ...                  0                0\n",
              "1          608   41  ...                  0                1\n",
              "2          502   42  ...                  0                0\n",
              "3          699   39  ...                  0                0\n",
              "4          850   43  ...                  0                1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW9eD6sk7zxY"
      },
      "source": [
        "Разделим на тренировочную и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNxvHrU-UDw2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(training_points, training_values, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXJsRLSZ8Hkw"
      },
      "source": [
        "Реализуем алгоритм, возвращающий важность признаков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_au3vyDuzzv",
        "outputId": "a8b1d89e-98f6-43ef-b01c-f3be940b3b13"
      },
      "source": [
        "\n",
        "class My_random_forest:\n",
        "  trees = []\n",
        "  columns = []\n",
        "  predictions = []\n",
        "\n",
        "  def fit(self, points, values, tree_count, k, sampsize):\n",
        "    for _ in range(0, tree_count):\n",
        "      points_i = points.sample(sampsize)\n",
        "      values_i = values[points_i.index]\n",
        "      columns_i = points_i.columns.to_numpy()\n",
        "      self.columns.append(columns_i)\n",
        "      tree_i = DecisionTreeClassifier(max_features=k)\n",
        "      tree_params_i = {'max_depth': np.arange(1, 10),'min_samples_leaf':np.arange(1,3)}\n",
        "      tree_grid_i = GridSearchCV(tree_i, tree_params_i)\n",
        "      tree_grid_i.fit(points_i, values_i)\n",
        "      self.trees.append(tree_grid_i)\n",
        "\n",
        "  def predict(self, points):\n",
        "    self.predictions = []\n",
        "    for i in range(0, len(self.trees)):\n",
        "      prediction_i = self.trees[i].predict(points[self.columns[i]])\n",
        "      self.predictions.append(prediction_i)\n",
        "    return self.voting()\n",
        "    \n",
        "  def voting(self):\n",
        "    voted_predictions = []\n",
        "    p = np.array(self.predictions)\n",
        "    for i in range(0, p.shape[1]):\n",
        "      voted_predictions.append(np.bincount(p[:,i]).argmax())\n",
        "    return np.array(voted_predictions)\n",
        "\n",
        "  def value_of_features(self, points, values):\n",
        "    permutated_points = points.copy()\n",
        "    feature_rating = []\n",
        "    point_names = permutated_points.columns\n",
        "    self.recent_accuracy = accuracy_score(values, self.predict(points))\n",
        "\n",
        "    for i in range(0, points.shape[1]):\n",
        "      permutated_points[point_names[i]] = np.array(points.iloc[:,i].sample(frac=1))\n",
        "      feature_rating.append([point_names[i], accuracy_score(values, self.predict(permutated_points)) - self.recent_accuracy])\n",
        "      permutated_points[point_names[i]] = np.array(points.iloc[:,i])\n",
        "\n",
        "    return feature_rating\n",
        "\n",
        "randfor = My_random_forest()\n",
        "k_obj = int(np.sqrt(X_train.shape[1]))\n",
        "view_samples_size = int(6667)\n",
        "randfor.fit(X_train, y_train, 125, k_obj, view_samples_size)\n",
        "pred = randfor.predict(X_test)\n",
        "accuracy_score(y_test, pred)\n",
        "ans = randfor.value_of_features(X_test, y_test)\n",
        "print(\"Значимые признаки: \")\n",
        "for i in range(len(ans)):\n",
        "  if ans[i][1] != 0:\n",
        "    print(ans[i][0], abs(ans[i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Значимые признаки: \n",
            "Age 0.05939393939393944\n",
            "Tenure 0.00060606060606061\n",
            "Balance 0.0060606060606061\n",
            "NumOfProducts 0.038484848484848566\n",
            "HasCrCard 0.00060606060606061\n",
            "IsActiveMember 0.021818181818181848\n",
            "EstimatedSalary 0.00121212121212122\n",
            "Gender_Female 0.0015151515151515804\n",
            "Gender_Male 0.00030303030303024947\n",
            "Geography_France 0.00060606060606061\n",
            "Geography_Spain 0.00060606060606061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4fd7kggziJf"
      },
      "source": [
        "Чем выше значение отклонения, тем важнее признак. Таким образом высокое значение играет кол-во продуктов, место жительства, возраст(на основе многочисленных запусков)\n"
      ]
    }
  ]
}